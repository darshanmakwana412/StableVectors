{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydiffvg\n",
    "import torch\n",
    "import skimage\n",
    "import skimage.io\n",
    "import random\n",
    "import ttools.modules\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"./panda.png\"\n",
    "num_paths = 500\n",
    "max_width = 2.0\n",
    "use_lpips_loss = False\n",
    "num_iter = 100\n",
    "use_blob = True\n",
    "\n",
    "pydiffvg.set_print_timing(False)\n",
    "\n",
    "gamma = 1.0\n",
    "\n",
    "# Use GPU if available\n",
    "pydiffvg.set_use_gpu(torch.cuda.is_available())\n",
    "\n",
    "perception_loss = ttools.modules.LPIPS().to(pydiffvg.get_device())\n",
    "\n",
    "#target = torch.from_numpy(skimage.io.imread('imgs/lena.png')).to(torch.float32) / 255.0\n",
    "target = skimage.io.imread(target)\n",
    "target = torch.from_numpy(target).to(torch.float32) / 255.0\n",
    "target = target.pow(gamma)\n",
    "target = target.to(pydiffvg.get_device())\n",
    "target = target.unsqueeze(0)\n",
    "target = target.permute(0, 3, 1, 2) # NHWC -> NCHW\n",
    "#target = torch.nn.functional.interpolate(target, size = [256, 256], mode = 'area')\n",
    "canvas_width, canvas_height = target.shape[3], target.shape[2]\n",
    "num_paths = num_paths\n",
    "max_width = max_width\n",
    "\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "shapes = []\n",
    "shape_groups = []\n",
    "if use_blob:\n",
    "    for i in range(num_paths):\n",
    "        num_segments = random.randint(3, 5)\n",
    "        num_control_points = torch.zeros(num_segments, dtype = torch.int32) + 2\n",
    "        points = []\n",
    "        p0 = (random.random(), random.random())\n",
    "        points.append(p0)\n",
    "        for j in range(num_segments):\n",
    "            radius = 0.05\n",
    "            p1 = (p0[0] + radius * (random.random() - 0.5), p0[1] + radius * (random.random() - 0.5))\n",
    "            p2 = (p1[0] + radius * (random.random() - 0.5), p1[1] + radius * (random.random() - 0.5))\n",
    "            p3 = (p2[0] + radius * (random.random() - 0.5), p2[1] + radius * (random.random() - 0.5))\n",
    "            points.append(p1)\n",
    "            points.append(p2)\n",
    "            if j < num_segments - 1:\n",
    "                points.append(p3)\n",
    "                p0 = p3\n",
    "        points = torch.tensor(points)\n",
    "        points[:, 0] *= canvas_width\n",
    "        points[:, 1] *= canvas_height\n",
    "        path = pydiffvg.Path(num_control_points = num_control_points,\n",
    "                                points = points,\n",
    "                                stroke_width = torch.tensor(1.0),\n",
    "                                is_closed = True)\n",
    "        shapes.append(path)\n",
    "        path_group = pydiffvg.ShapeGroup(shape_ids = torch.tensor([len(shapes) - 1]),\n",
    "                                            fill_color = torch.tensor([random.random(),\n",
    "                                                                    random.random(),\n",
    "                                                                    random.random(),\n",
    "                                                                    random.random()]))\n",
    "        shape_groups.append(path_group)\n",
    "else:\n",
    "    for i in range(num_paths):\n",
    "        num_segments = random.randint(1, 3)\n",
    "        num_control_points = torch.zeros(num_segments, dtype = torch.int32) + 2\n",
    "        points = []\n",
    "        p0 = (random.random(), random.random())\n",
    "        points.append(p0)\n",
    "        for j in range(num_segments):\n",
    "            radius = 0.05\n",
    "            p1 = (p0[0] + radius * (random.random() - 0.5), p0[1] + radius * (random.random() - 0.5))\n",
    "            p2 = (p1[0] + radius * (random.random() - 0.5), p1[1] + radius * (random.random() - 0.5))\n",
    "            p3 = (p2[0] + radius * (random.random() - 0.5), p2[1] + radius * (random.random() - 0.5))\n",
    "            points.append(p1)\n",
    "            points.append(p2)\n",
    "            points.append(p3)\n",
    "            p0 = p3\n",
    "        points = torch.tensor(points)\n",
    "        points[:, 0] *= canvas_width\n",
    "        points[:, 1] *= canvas_height\n",
    "        #points = torch.rand(3 * num_segments + 1, 2) * min(canvas_width, canvas_height)\n",
    "        path = pydiffvg.Path(num_control_points = num_control_points,\n",
    "                                points = points,\n",
    "                                stroke_width = torch.tensor(1.0),\n",
    "                                is_closed = False)\n",
    "        shapes.append(path)\n",
    "        path_group = pydiffvg.ShapeGroup(shape_ids = torch.tensor([len(shapes) - 1]),\n",
    "                                            fill_color = None,\n",
    "                                            stroke_color = torch.tensor([random.random(),\n",
    "                                                                        random.random(),\n",
    "                                                                        random.random(),\n",
    "                                                                        random.random()]))\n",
    "        shape_groups.append(path_group)\n",
    "\n",
    "scene_args = pydiffvg.RenderFunction.serialize_scene(\\\n",
    "    canvas_width, canvas_height, shapes, shape_groups)\n",
    "\n",
    "render = pydiffvg.RenderFunction.apply\n",
    "img = render(canvas_width, # width\n",
    "                canvas_height, # height\n",
    "                2,   # num_samples_x\n",
    "                2,   # num_samples_y\n",
    "                0,   # seed\n",
    "                None,\n",
    "                *scene_args)\n",
    "pydiffvg.imwrite(img.cpu(), './init.png', gamma=gamma)\n",
    "\n",
    "points_vars = []\n",
    "stroke_width_vars = []\n",
    "color_vars = []\n",
    "for path in shapes:\n",
    "    path.points.requires_grad = True\n",
    "    points_vars.append(path.points)\n",
    "if not use_blob:\n",
    "    for path in shapes:\n",
    "        path.stroke_width.requires_grad = True\n",
    "        stroke_width_vars.append(path.stroke_width)\n",
    "if use_blob:\n",
    "    for group in shape_groups:\n",
    "        group.fill_color.requires_grad = True\n",
    "        color_vars.append(group.fill_color)\n",
    "else:\n",
    "    for group in shape_groups:\n",
    "        group.stroke_color.requires_grad = True\n",
    "        color_vars.append(group.stroke_color)\n",
    "\n",
    "# Optimize\n",
    "points_optim = torch.optim.Adam(points_vars, lr=1.0)\n",
    "if len(stroke_width_vars) > 0:\n",
    "    width_optim = torch.optim.Adam(stroke_width_vars, lr=0.1)\n",
    "color_optim = torch.optim.Adam(color_vars, lr=0.01)\n",
    "\n",
    "# Adam iterations.\n",
    "for t in tqdm(range(num_iter)):\n",
    "    # print('iteration:', t)\n",
    "    points_optim.zero_grad()\n",
    "    if len(stroke_width_vars) > 0:\n",
    "        width_optim.zero_grad()\n",
    "    color_optim.zero_grad()\n",
    "    # Forward pass: render the image.\n",
    "    scene_args = pydiffvg.RenderFunction.serialize_scene(canvas_width, canvas_height, shapes, shape_groups)\n",
    "    img = render(canvas_width, # width\n",
    "                    canvas_height, # height\n",
    "                    2,   # num_samples_x\n",
    "                    2,   # num_samples_y\n",
    "                    t,   # seed\n",
    "                    None,\n",
    "                    *scene_args)\n",
    "    # Compose img with white background\n",
    "    img = img[:, :, 3:4] * img[:, :, :3] + torch.ones(img.shape[0], img.shape[1], 3, device = pydiffvg.get_device()) * (1 - img[:, :, 3:4])\n",
    "    # Save the intermediate render.\n",
    "    # pydiffvg.imwrite(img.cpu(), 'results/iter_{}.png'.format(t), gamma=gamma)\n",
    "    img = img[:, :, :3]\n",
    "    # Convert img from HWC to NCHW\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.permute(0, 3, 1, 2) # NHWC -> NCHW\n",
    "    if use_lpips_loss:\n",
    "        loss = perception_loss(img, target) + (img.mean() - target.mean()).pow(2)\n",
    "    else:\n",
    "        loss = (img - target).pow(2).mean()\n",
    "    # print('render loss:', loss.item())\n",
    "\n",
    "    # Backpropagate the gradients.\n",
    "    loss.backward()\n",
    "\n",
    "    # Take a gradient descent step.\n",
    "    points_optim.step()\n",
    "    if len(stroke_width_vars) > 0:\n",
    "        width_optim.step()\n",
    "    color_optim.step()\n",
    "    if len(stroke_width_vars) > 0:\n",
    "        for path in shapes:\n",
    "            path.stroke_width.data.clamp_(1.0, max_width)\n",
    "    if use_blob:\n",
    "        for group in shape_groups:\n",
    "            group.fill_color.data.clamp_(0.0, 1.0)\n",
    "    else:\n",
    "        for group in shape_groups:\n",
    "            group.stroke_color.data.clamp_(0.0, 1.0)\n",
    "\n",
    "    # if t % 10 == 0 or t == num_iter - 1:\n",
    "    #     pydiffvg.save_svg('results/painterly_rendering/iter_{}.svg'.format(t), canvas_width, canvas_height, shapes, shape_groups)\n",
    "\n",
    "img = render(canvas_width, # width\n",
    "                canvas_height, # height\n",
    "                2,   # num_samples_x\n",
    "                2,   # num_samples_y\n",
    "                0,   # seed\n",
    "                None,\n",
    "                *scene_args)\n",
    "# Compose img with white background\n",
    "img = img[:, :, 3:4] * img[:, :, :3] + torch.ones(img.shape[0], img.shape[1], 3, device = pydiffvg.get_device()) * (1 - img[:, :, 3:4])\n",
    "# Save the intermediate render.\n",
    "pydiffvg.imwrite(img.cpu(), './final.png'.format(t), gamma=gamma)\n",
    "\n",
    "# pydiffvg.imwrite(img.cpu(), './final.png'.format(t), gamma=gamma)\n",
    "# Render the final result.\n",
    "# img = render(target.shape[1], # width\n",
    "#                 target.shape[0], # height\n",
    "#                 2,   # num_samples_x\n",
    "#                 2,   # num_samples_y\n",
    "#                 0,   # seed\n",
    "#                 None,\n",
    "#                 *scene_args)\n",
    "# Save the intermediate render.\n",
    "# pydiffvg.imwrite(img.cpu(), './final.png'.format(t), gamma=gamma)\n",
    "# Convert the intermediate renderings to a video.\n",
    "# from subprocess import call\n",
    "# call([\"ffmpeg\", \"-framerate\", \"24\", \"-i\",\n",
    "#     \"results/painterly_rendering/iter_%d.png\", \"-vb\", \"20M\",\n",
    "#     \"results/painterly_rendering/out.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(device)\n",
    "\n",
    "model = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(model, torch_dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a teapot.\"\n",
    "caption = \" minimal flat 2d vector icon\"\n",
    "prompt = caption + prompt\n",
    "image = pipeline(prompt).images[0] \n",
    "image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save(\"./teapot.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
